{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flood_water_classification_ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahryaramd/flood-mapping/blob/master/flood_water_classification_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/shahryaramd/flood-mapping/blob/master/flood_water_classification_ml.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG1l92J7DwRo",
        "colab_type": "text"
      },
      "source": [
        "Written by Shahryar Ahmad (skahmad@uw.edu)\n",
        "\n",
        "*(modified from [TF_demo1_keras.ipynb](https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb))*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC8adBmw-5m3",
        "colab_type": "text"
      },
      "source": [
        "# Steps followed: \n",
        "\n",
        "1.   Exporting training/testing data from Earth Engine in TFRecord format - Four flood events in US.\n",
        "2.   Preparing the data for use in a TensorFlow model.\n",
        "2.   Training and validating a Sequential model in TensorFlow.\n",
        "3.   Making predictions on image data exported from Earth Engine in TFRecord format.\n",
        "4.   Ingesting classified image data to Earth Engine in TFRecord format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejxa1MQjEGv9",
        "colab_type": "text"
      },
      "source": [
        "## Authenticate to Earth Engine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzwiVqbcmJIX",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzskjNXYJ06D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ70EsoWND_0",
        "colab_type": "text"
      },
      "source": [
        "## Test the TensorFlow installation\n",
        "\n",
        "Import the TensorFlow library and check the version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1PrYRLaVw_g",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import folium\n",
        "from pprint import pprint\n",
        "\n",
        "print(folium.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrXLkJC2QJdP",
        "colab_type": "text"
      },
      "source": [
        "# Define variables\n",
        "\n",
        "This set of global variables will be used throughout.  Need a Cloud Storage bucket to which files will be written. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzIJVWT1Nr1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_DATA = ee.FeatureCollection(\"users/shahryarahmad/labeldata_floodmap\") ## label data prepared from GEE, exported as an asset\n",
        "print(LABEL_DATA.getInfo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTOc5YLQZ5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Earth Engine username.  This is used to import a classified image\n",
        "# into your Earth Engine assets folder.\n",
        "USER_NAME = 'shahryarahmad'\n",
        "\n",
        "# Cloud Storage bucket into which training, testing and prediction \n",
        "# datasets will be written.\n",
        "OUTPUT_BUCKET = 'water-classification-sensitivity'\n",
        "\n",
        "# Use Sentinel-1 SAR for preliminary classification, conservative threshold of -24dB used\n",
        "THRESHOLD = -24\n",
        "\n",
        "s1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
        "srtm = ee.Image(\"USGS/SRTMGL1_003\");\n",
        "\n",
        "# Use these bands for prediction.\n",
        "BANDS = ['VV-flood','VH-flood','VV-noflood','VH-noflood','elevation','slope']\n",
        "\n",
        "# The labels, consecutive integer indices starting from zero, are stored in\n",
        "# this property, set on each point.\n",
        "LABEL = 'landuse'\n",
        "# Number of label values, i.e. number of classes in the classification.\n",
        "N_CLASSES = 3\n",
        "\n",
        "# These names are used to specify properties in the export of\n",
        "# training/testing data and to define the mapping between names and data\n",
        "# when reading into TensorFlow datasets.\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "# File names for the training and testing datasets.  These TFRecord files\n",
        "# will be exported from Earth Engine into the Cloud Storage bucket.\n",
        "TRAIN_FILE_PREFIX = 'Training_water_all' \n",
        "TEST_FILE_PREFIX = 'Testing_water_all' \n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcjQnHH8zT4q",
        "colab_type": "text"
      },
      "source": [
        "# Get Training and Testing data from Earth Engine\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJYucYe3SPPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#//*******************  SENTINEL SAR 1 PROCESSING  ***********************************************************\n",
        "\n",
        "# Threshold for look angle used to remove erroneous data at far edges of images\n",
        "angle_threshold_1 = ee.Number(45.4);\n",
        "angle_threshold_2 = ee.Number(31.66)\n",
        "\n",
        "# Define focal median function\n",
        "def focal_median(img):\n",
        "  fm = img.focal_max(30, 'circle', 'meters')\n",
        "  # print(fm.getInfo())\n",
        "  fm = fm.rename([\"VV_Smooth\", \"VH_Smooth\"])\n",
        "  return img.addBands(fm)\n",
        "\n",
        "\n",
        "def smoothing(img):\n",
        "  boxcar = ee.Kernel.circle(radius = 1, units = 'pixels', magnitude = 1);\n",
        "\n",
        "  # Closing operation\n",
        "  smooth = img.focal_max(kernel = boxcar, iterations = 1).focal_min(kernel = boxcar, iterations = 1)\n",
        "  # Smooth the image by convolving with the boxcar kernel.\n",
        "  # smooth = img.convolve(boxcar);\n",
        "  smooth = smooth.rename(\"Smooth\")\n",
        "  return img.addBands(smooth)\n",
        "\n",
        "# Define masking function for removing erroneous pixels\n",
        "def mask_by_angle(img):\n",
        "  angle = img.select('angle');\n",
        "  vv = img.select('VH');\n",
        "  mask1 = angle.lt(angle_threshold_1);\n",
        "  mask2 = angle.gt(angle_threshold_2);\n",
        "  vv = vv.updateMask(mask1);\n",
        "  return vv.updateMask(mask2);\n",
        "\n",
        "def mask_by_angle_VV(img):\n",
        "  angle = img.select('angle');\n",
        "  vv = img.select('VV');\n",
        "  mask1 = angle.lt(angle_threshold_1);\n",
        "  mask2 = angle.gt(angle_threshold_2);\n",
        "  vv = vv.updateMask(mask1);\n",
        "  return vv.updateMask(mask2);\n",
        "\n",
        "### Prepare SAR imagery for training over multiple regions\n",
        "\n",
        "houston =  ee.Geometry.Point([-95.76422509388891, 29.46698384300668])\n",
        "florence = ee.Geometry.Point([-78.30901300007325, 34.642647795510356])\n",
        "missouri = ee.Geometry.Point([-97.925274609375, 40.572107759969555])\n",
        "arkansas = ee.Geometry.Point([-93.07378231277586, 35.20230235842815])\n",
        "\n",
        "# eg 4. arkansas\n",
        "date_range_ar = ee.DateRange('2019-01-01','2019-01-20');\n",
        "date_range2_ar = ee.DateRange('2019-05-25','2019-05-30');\n",
        "\n",
        "# eg 3. missouri\n",
        "date_range_mi = ee.DateRange('2019-08-01','2019-08-20');\n",
        "date_range2_mi = ee.DateRange('2019-03-13','2019-03-25');\n",
        "\n",
        "\n",
        "# eg 2. florence\n",
        "date_range_fl = ee.DateRange('2018-08-07','2018-08-20');\n",
        "date_range2_fl = ee.DateRange('2018-09-17','2018-09-29');\n",
        "\n",
        "\n",
        "# eg 1. harvey\n",
        "date_range_ho = ee.DateRange('2017-06-07','2017-06-09');\n",
        "date_range2_ho = ee.DateRange('2017-08-25','2017-08-30');\n",
        "\n",
        "\n",
        "#non-flooded\n",
        "s1nf_houston = s1\\\n",
        "  .filterDate(date_range_ho)\\\n",
        "  .filterBounds(houston)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1nf_florence = s1\\\n",
        "  .filterDate(date_range_fl)\\\n",
        "  .filterBounds(florence)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1nf_arkansas = s1\\\n",
        "  .filterDate(date_range_ar)\\\n",
        "  .filterBounds(arkansas)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1nf_missouri = s1\\\n",
        "  .filterDate(date_range_mi)\\\n",
        "  .filterBounds(missouri)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1_noflood = ee.ImageCollection.fromImages([s1nf_houston.first(), s1nf_florence.first(),\n",
        "                                  s1nf_missouri.first(), s1nf_arkansas.first()]).mosaic()\n",
        "\n",
        "vh_noflood = mask_by_angle(s1_noflood)\n",
        "vv_noflood = mask_by_angle_VV(s1_noflood)\n",
        "vv_noflood = vv_noflood.addBands(vh_noflood.select('VH'))\n",
        "vv_noflood = focal_median(vv_noflood)  # has 4 bands: VV, VH, VV_Smooth, VH_Smooth\n",
        "vv_noflood = vv_noflood.select([\"VV_Smooth\", \"VH_Smooth\"]).rename(['VV-noflood','VH-noflood'])\n",
        " \n",
        "\n",
        "## Flooded image\n",
        "\n",
        "s1f_houston = s1\\\n",
        "  .filterDate(date_range2_ho)\\\n",
        "  .filterBounds(houston)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1f_florence = s1\\\n",
        "  .filterDate(date_range2_fl)\\\n",
        "  .filterBounds(florence)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1f_arkansas = s1\\\n",
        "  .filterDate(date_range2_ar)\\\n",
        "  .filterBounds(arkansas)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1f_missouri = s1\\\n",
        "  .filterDate(date_range2_mi)\\\n",
        "  .filterBounds(missouri)\\\n",
        "  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "  .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "\n",
        "s1_flood = ee.ImageCollection.fromImages([s1f_houston.first(), s1f_florence.first(), s1f_missouri.first(), s1f_arkansas.first()]).mosaic()\n",
        "\n",
        "vh_flood = mask_by_angle(s1_flood)\n",
        "vv_flood = mask_by_angle_VV(s1_flood)\n",
        "vv_flood = vv_flood.addBands(vh_flood.select('VH'))\n",
        "vv_flood = focal_median(vv_flood)  # has 4 bands: VV, VH, VV_Smooth, VH_Smooth\n",
        "vv_flood = vv_flood.select([\"VV_Smooth\", \"VH_Smooth\"]).rename(['VV-flood','VH-flood'])\n",
        " \n",
        "def radians(img): \n",
        "  return img.toFloat().multiply(3.14159).divide(180)\n",
        "\n",
        "\t\t\n",
        "## IMAGE TO TRAIN\n",
        "import math\n",
        "terrain = ee.Algorithms.Terrain(srtm);\n",
        "slope = radians(terrain.select('slope'))\n",
        "aspect = radians(terrain.select('aspect'))\n",
        "\n",
        "image = vv_flood.addBands(vv_noflood.select('VV-noflood'))\\\n",
        "                .addBands(vv_noflood.select('VH-noflood')) \\\n",
        "                .addBands(srtm.select('elevation').double()) \\\n",
        "                .addBands(slope.select('slope'))\n",
        "                \n",
        "print('final image',image.getInfo())\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "mapid = image.getMapId({'bands': ['VH-noflood'], 'min': -30, 'max': 0})\n",
        "map = folium.Map(location=[29.4977, -95.36524])\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEeyPf3zSPct",
        "colab_type": "text"
      },
      "source": [
        "## Add pixel values of the composite to labeled points\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOedOKyRExHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample the image at the points and add a random column.\n",
        "sample = image.sampleRegions(\n",
        "  collection=LABEL_DATA, properties=[LABEL], scale=30).randomColumn()\n",
        "\n",
        "# Partition the sample approximately 70-30.\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "testing = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "\n",
        "# Print the first couple points to verify.\n",
        "pprint({'training': training.first().getInfo()})\n",
        "pprint({'testing': testing.first().getInfo()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNc7a2nRR4MI",
        "colab_type": "text"
      },
      "source": [
        "## Export the training and testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb-aPvQc0Xvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure you can see the output bucket.  You must have write access.\n",
        "print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + OUTPUT_BUCKET) \n",
        "    else 'Can not find output Cloud Storage bucket.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVNQzg8R6Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the tasks.\n",
        "training_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=training,\n",
        "  description='Training Export',\n",
        "  fileNamePrefix=TRAIN_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=testing,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=TEST_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4WGIekaS2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start the tasks.\n",
        "training_task.start()\n",
        "testing_task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7nFLuySISeC",
        "colab_type": "text"
      },
      "source": [
        "### Monitor task progress\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWvS5ekcEq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print all tasks.\n",
        "pprint(ee.batch.Task.list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43-c0JNFI_m6",
        "colab_type": "text"
      },
      "source": [
        "### Check existence of the exported files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDZfNl6yc0Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Found training file.' if tf.io.gfile.exists(TRAIN_FILE_PATH) \n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.io.gfile.exists(TEST_FILE_PATH) \n",
        "    else 'No testing file found.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA8QA8oQVo8V",
        "colab_type": "text"
      },
      "source": [
        "## Export the imagery to classify\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4vgaZRnm71d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File name for the prediction (image) dataset.  The trained model will read\n",
        "# this dataset and make predictions in each pixel.\n",
        "\n",
        "## Specify events for testing \n",
        "kerala =   ee.Geometry.Point([76.19201793332346, 10.432244570388278])\n",
        "mozam =   ee.Geometry.Point([34.53572525279313, -19.650222084488128])\n",
        "srilanka =   ee.Geometry.Point([80.19579864227894,6.100260555152524])\n",
        "nsw = ee.Geometry.Point([147.97393175933806, -33.3861002551131])\n",
        "ls =  ee.Geometry.Point([106.7087175776598, 14.869266407333143])\n",
        "\n",
        "# ID of event for exporting \n",
        "floodID = 'nebraska'  #\n",
        "IMAGE_FILE_PREFIX = 'Image_pixel_'  + floodID + '_'\n",
        "\n",
        "# The output path for the classified image (i.e. predictions) TFRecord file.\n",
        "OUTPUT_IMAGE_FILE = 'gs://' + OUTPUT_BUCKET + '/Classified_pixel_' + floodID + '.TFRecord'\n",
        "\n",
        "# The name of the Earth Engine asset to be created by importing\n",
        "# the classified image from the TFRecord file in Cloud Storage.\n",
        "OUTPUT_ASSET_ID = 'users/' + USER_NAME + '/Classified_pixel_' + floodID +'_withdem'\n",
        "\n",
        "\n",
        "# Export imagery in this region.\n",
        "## harvey\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[-96.47401392967757, 29.681041119196202],\n",
        "#           [-96.47401392967757, 29.164301460271606],\n",
        "#           [-95.02381861717757, 29.164301460271606],\n",
        "#           [-95.02381861717757, 29.681041119196202]]]);    \n",
        "\n",
        "## eg 2. florence\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[-78.67341578514632, 34.712405817452094],\n",
        "#           [-78.67341578514632, 34.134681521103936],\n",
        "#           [-77.7986294081932, 34.134681521103936],\n",
        "#           [-77.7986294081932, 34.712405817452094]]]);\n",
        "\n",
        "# eg 3. extent_missouri\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[-98.7765771200875, 41.479444734972475],\n",
        "#           [-98.7765771200875, 40.965048314605184],\n",
        "#           [-97.29616940524375, 40.965048314605184],\n",
        "#           [-97.29616940524375, 41.479444734972475]]]);\n",
        "\n",
        "## eg 4. extent_arkansas\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[-94.18336451561507, 35.52342267961415],\n",
        "#           [-94.18336451561507, 35.04812504434383],\n",
        "#           [-92.52168238670882, 35.04812504434383],\n",
        "#           [-92.52168238670882, 35.52342267961415]]]);\n",
        "\n",
        "# ## eg 5. extent_kerala\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[76.16033503714692, 10.507022269292058],\n",
        "#           [76.16033503714692, 10.16792189672564],\n",
        "#           [76.39860102835786, 10.16792189672564],\n",
        "#           [76.39860102835786, 10.507022269292058]]])\n",
        "\n",
        "## eg 5. extent_keralabig\n",
        "# EXTENT_TO_CLASSIFY =  ee.Geometry.Polygon(\n",
        "#         [[[76.12188288870942, 10.507022269292058],\n",
        "#           [76.12188288870942, 10.019197933519012],\n",
        "#           [76.40684077445161, 10.019197933519012],\n",
        "#           [76.40684077445161, 10.507022269292058]]])\n",
        "\n",
        "## eg 6. extent_mozam\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[34.20765164882542, -19.55762825258411],\n",
        "#           [34.20765164882542, -20.23169905138531],\n",
        "#           [34.74872830898167, -20.23169905138531],\n",
        "#           [34.74872830898167, -19.55762825258411]]])\n",
        "\n",
        "\n",
        "## eg 7. extent_sl\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[80.15206589484337, 6.1372608569348674],\n",
        "#           [80.15206589484337, 6.047135541681527],\n",
        "#           [80.26810898566369, 6.047135541681527],\n",
        "#           [80.26810898566369, 6.1372608569348674]]])\n",
        "\n",
        "## eg . extent_ns\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[147.74177168252993, -33.27416512270075],\n",
        "#           [147.74177168252993, -33.575837125375116],\n",
        "#           [148.24987862947512, -33.575837125375116],\n",
        "#           [148.24987862947512, -33.27416512270075]]])\n",
        "\n",
        "\n",
        "## eg . extent_ur\n",
        "# EXTENT_TO_CLASSIFY = ee.Geometry.Polygon(\n",
        "#         [[[-58.22185802449711, -31.253794836847117],\n",
        "#           [-58.22185802449711, -31.607886792184388],\n",
        "#           [-57.80423541905268, -31.607886792184388],\n",
        "#           [-57.80423541905268, -31.253794836847117]]])\n",
        "# ur = ee.Geometry.Point([-58.024852474945625, -31.43463428309628])\n",
        "\n",
        "# extent_ls \n",
        "# EXTENT_TO_CLASSIFY=  ee.Geometry.Polygon(\n",
        "#         [[[106.36773892289094, 15.361705008559696],\n",
        "#           [106.36773892289094, 14.543123762883898],\n",
        "#           [107.12038823014191, 14.543123762883898],\n",
        "#           [107.12038823014191, 15.361705008559696]]]);\n",
        "\n",
        "sn = ee.Geometry.Point([-97.205985, 42.791281])\n",
        "# extent_sn\n",
        "EXTENT_TO_CLASSIFY =    ee.Geometry.Polygon(\n",
        "        [[[-97.56520653959635, 43.10070218967456],\n",
        "          [-97.56520653959635, 42.64280371531401],\n",
        "          [-96.47685731645944, 42.64280371531401],\n",
        "          [-96.47685731645944, 43.10070218967456]]]);\n",
        "\n",
        "# eg 12. nebraska\n",
        "date_range_sn = ee.DateRange('2018-11-10','2018-11-20');\n",
        "date_range2_sn = ee.DateRange('2019-03-16','2019-03-20');\n",
        "\n",
        "\n",
        "#eg 12. ls\n",
        "# date_range_ls = ee.DateRange('2017-05-18','2017-05-20');\n",
        "# date_range2_ls = ee.DateRange('2018-07-24','2018-07-26');\n",
        "\n",
        "\n",
        "\n",
        "#eg 9. ns\n",
        "# date_range_ns = ee.DateRange('2016-08-01','2016-08-15');\n",
        "# date_range2_ns = ee.DateRange('2016-09-27','2016-09-28');\n",
        "\n",
        "# eg 7. sl\n",
        "# date_range_sl = ee.DateRange('2017-01-10','2017-01-25');\n",
        "# date_range2_sl = ee.DateRange('2017-05-28','2017-05-31');\n",
        "\n",
        "# # eg 6. mozam\n",
        "# date_range_mz = ee.DateRange('2019-03-10','2019-03-15');\n",
        "# date_range2_mz = ee.DateRange('2019-03-18','2019-03-25');\n",
        "\n",
        "\n",
        "# eg 5. kerala\n",
        "# date_range_kr = ee.DateRange('2018-03-01','2018-03-20');\n",
        "# date_range2_kr = ee.DateRange('2019-08-05','2019-08-12');\n",
        "\n",
        "# eg 4. arkansas\n",
        "# date_range = ee.DateRange('2019-01-01','2019-01-20');\n",
        "# date_range2 = ee.DateRange('2019-05-25','2019-05-30');\n",
        "\n",
        "# eg 3. missouri\n",
        "# var date_range = ee.DateRange('2019-08-01','2019-08-20');\n",
        "# var date_range2 = ee.DateRange('2019-03-13','2019-03-25');\n",
        "\n",
        "# eg 2. florence\n",
        "# date_range = ee.DateRange('2018-08-07','2018-08-20');\n",
        "# date_range2 = ee.DateRange('2018-09-17','2018-09-29');\n",
        "\n",
        "\n",
        "S1 = s1\\\n",
        "\t\t  .filterDate(date_range_sn)\\\n",
        "\t\t  .filterBounds(sn)\\\n",
        "\t\t  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "\t\t  .filter(ee.Filter.eq('instrumentMode', 'IW')).first()\n",
        "\n",
        "vh_noflood = mask_by_angle(S1)\n",
        "vv_noflood = mask_by_angle_VV(S1)\n",
        "vv_noflood = vv_noflood.addBands(vh_noflood.select('VH'))\n",
        "vv_noflood = focal_median(vv_noflood)  # has 4 bands: VV, VH, VV_Smooth, VH_Smooth\n",
        "vv_noflood = vv_noflood.select([\"VV_Smooth\", \"VH_Smooth\"]).rename(['VV-noflood','VH-noflood'])\n",
        " \n",
        "\n",
        "S1 = s1\\\n",
        "\t\t  .filterDate(date_range2_sn)\\\n",
        "\t\t  .filterBounds(sn)\\\n",
        "\t\t  .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "\t\t  .filter(ee.Filter.eq('instrumentMode', 'IW')).first()\n",
        "\n",
        "vh_flood = mask_by_angle(S1)\n",
        "vv_flood = mask_by_angle_VV(S1)\n",
        "vv_flood = vv_flood.addBands(vh_flood.select('VH'))\n",
        "vv_flood = focal_median(vv_flood)  # has 4 bands: VV, VH, VV_Smooth, VH_Smooth\n",
        "vv_flood = vv_flood.select([\"VV_Smooth\", \"VH_Smooth\"]).rename(['VV-flood','VH-flood']) \n",
        "\n",
        "## IMAGE TO CLASSIFY DURING TESTING\n",
        "import math\n",
        "terrain = ee.Algorithms.Terrain(srtm);\n",
        "slope = radians(terrain.select('slope'))\n",
        "aspect = radians(terrain.select('aspect'))\n",
        "\n",
        "image_to_classify = vv_flood.addBands(vv_noflood.select('VV-noflood')) \\\n",
        "                .addBands(vv_noflood.select('VH-noflood')) \\\n",
        "                .addBands(srtm.select('elevation').double()) \\\n",
        "                .addBands(slope.select('slope'))\n",
        "\n",
        "print(image_to_classify.getInfo())\n",
        "# Use folium to visualize the imagery.\n",
        "mapid = image_to_classify.getMapId({'bands': ['VH-flood'], 'min': -30, 'max': 0})\n",
        "map = folium.Map(location=[42.791281,-97.205985])\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVNhJYacVpEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify patch and file dimensions.\n",
        "image_export_options = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'maxFileSize': 104857600,\n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Setup the task.\n",
        "\n",
        "image_task = ee.batch.Export.image.toCloudStorage(\n",
        "  image=image_to_classify,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=IMAGE_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  scale=30,\n",
        "  fileFormat='TFRecord',\n",
        "  region=EXTENT_TO_CLASSIFY.toGeoJSON()['coordinates'],\n",
        "  formatOptions=image_export_options,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SweCkHDaNE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start the task.\n",
        "image_task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC8C53MRTG_E",
        "colab_type": "text"
      },
      "source": [
        "### Monitor task progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKZeZswloP11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "while image_task.active():\n",
        "  print('Polling for task (id: {}).'.format(image_task.id))\n",
        "  print(image_task.status())\n",
        "  time.sleep(30)\n",
        "print('Done with image export.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWdH_wlZCEk",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation and pre-processing\n",
        "\n",
        "Read data from the TFRecord file into a `tf.data.Dataset`.  Pre-process the dataset to get it into a suitable format for input to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS4jGTrEfz-1",
        "colab_type": "text"
      },
      "source": [
        "## Read into a `tf.data.Dataset`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3PKyDQW8Vpx",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
        "# Print the first record to check.\n",
        "print(iter(train_dataset).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrDYm-ibKR6t",
        "colab_type": "text"
      },
      "source": [
        "## Define the structure of your data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6JVQV5HKHMZ",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
        "\n",
        "pprint(features_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNfaUPbcjuCO",
        "colab_type": "text"
      },
      "source": [
        "## Parse the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Q0g3fBj2kD",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.transpose(list(inputs.values())),\n",
        "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "pprint(iter(parsed_dataset).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEx1RAXOZQkS",
        "colab_type": "text"
      },
      "source": [
        "# NN Model setup\n",
        "\n",
        "The workflow for classification in TensorFlow is:\n",
        "\n",
        "1.  Create the model.\n",
        "2.  Train the model (i.e. `fit()`).\n",
        "3.  Use the trained model for inference (i.e. `predict()`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9pWa54oG-xl",
        "colab_type": "text"
      },
      "source": [
        "## Create the Keras model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCZq3VNpG--G",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "input_dataset = parsed_dataset \n",
        "\n",
        "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
        "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
        "# the label needs to be turned into a one-hot vector.\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.transpose(list(inputs.values())),\n",
        "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
        "\n",
        "# Map the to_tuple function, shuffle and batch.\n",
        "input_dataset = input_dataset.map(to_tuple).batch(8)\n",
        "\n",
        "# Define the layers in the model.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l = 0.001)),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l = 0.001)),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l = 0.001)),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model with the specified loss function.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(x=input_dataset, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4ex_4eKiyb",
        "colab_type": "text"
      },
      "source": [
        "## Check model accuracy on the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE6d7FsrMa1p",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(to_tuple)\n",
        "    .batch(1))\n",
        "\n",
        "model.evaluate(test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhHrnv3VR0DU",
        "colab_type": "text"
      },
      "source": [
        "# Testing - Use the trained model to classify an image from Earth Engine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWoXz04CDQ0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(to_tuple)\n",
        "    .batch(1))\n",
        "\n",
        "## Load pre-saved model\n",
        "\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/My Drive/flood-mapping-GEEexports/model_withdem_0p95')\n",
        "model = loaded_model\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmTayDitZgQ5",
        "colab_type": "text"
      },
      "source": [
        "## Find the image files and JSON mixer file in Cloud Storage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUv9WMpcVp8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a list of all the files in the output bucket.\n",
        "files_list = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n",
        "# Get only the files generated by the image export.\n",
        "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "image_files_list = []\n",
        "json_file = None\n",
        "for f in exported_files_list:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    image_files_list.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    json_file = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "image_files_list.sort()\n",
        "\n",
        "pprint(image_files_list)\n",
        "print(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcjYG9fk53xL",
        "colab_type": "text"
      },
      "source": [
        "## Read the JSON mixer file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn7Dr0AAd93_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "# Load the contents of the mixer file to a JSON object.\n",
        "json_text = !gsutil cat {json_file}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(json_text.nlstr)\n",
        "pprint(mixer)\n",
        "\n",
        "print(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xyzyPPJwpVI",
        "colab_type": "text"
      },
      "source": [
        "## Read the image files into a dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn8Kj3VfwpiJ",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Get relevant info from the JSON mixer file.\n",
        "patch_width = mixer['patchDimensions'][0]\n",
        "patch_height = mixer['patchDimensions'][1]\n",
        "patches = mixer['totalPatches']\n",
        "patch_dimensions_flat = [patch_width * patch_height, 1]\n",
        "\n",
        "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
        "image_columns = [\n",
        "  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) \n",
        "    for k in BANDS\n",
        "]\n",
        "\n",
        "# Parsing dictionary.\n",
        "image_features_dict = dict(zip(BANDS, image_columns))\n",
        "\n",
        "# Note that you can make one dataset from many files by specifying a list.\n",
        "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
        "\n",
        "# Parsing function.\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, image_features_dict)\n",
        "\n",
        "# Parse the data into tensors, one long tensor per patch.\n",
        "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
        "\n",
        "# Break our long tensors into many little ones.\n",
        "image_dataset = image_dataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "\n",
        "# Turn the dictionary in each record into a tuple without a label.\n",
        "image_dataset = image_dataset.map(\n",
        "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
        ")\n",
        "\n",
        "# Turn each patch into a batch.\n",
        "image_dataset = image_dataset.batch(patch_width * patch_height)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2sfRemRRDkV",
        "colab_type": "text"
      },
      "source": [
        "## Generate predictions for the image pixels\n",
        "\n",
        "To get predictions in each pixel, run the image dataset through the trained model using `model.predict()`.  Print the first prediction to see that the output is a list of the three class probabilities for each pixel.  Running all predictions might take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGhmiP_REBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run prediction in batches, with as many steps as there are patches.\n",
        "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
        "\n",
        "# Note that the predictions come as a numpy array.  Check the first one.\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPU2VlPOikAy",
        "colab_type": "text"
      },
      "source": [
        "## Write the predictions to a TFRecord file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkorbsEHepzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Writing to file ' + OUTPUT_IMAGE_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATMknHc0qeR",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the writer.\n",
        "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
        "\n",
        "# Every patch-worth of predictions we'll dump an example into the output\n",
        "# file with a single feature that holds our predictions. Since our predictions\n",
        "# are already in the order of the exported data, the patches we create here\n",
        "# will also be in the right order.\n",
        "patch = [[], [], [], []]\n",
        "cur_patch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  # Once we've seen a patches-worth of class_ids...\n",
        "  if (len(patch[0]) == patch_width * patch_height):\n",
        "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              int64_list=tf.train.Int64List(\n",
        "                  value=patch[0])),\n",
        "          'nowater': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'permwater': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'floodwater': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example to the file and clear our patch array so it's ready for\n",
        "    # another batch of class ids\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], []]\n",
        "    cur_patch += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K_1hKs0aBdA",
        "colab_type": "text"
      },
      "source": [
        "# Upload the classifications to an Earth Engine asset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6sNZXWOSa82",
        "colab_type": "text"
      },
      "source": [
        "## Verify the existence of the predictions file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVWDPefUCgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls -l {OUTPUT_IMAGE_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZyCo297Clcx",
        "colab_type": "text"
      },
      "source": [
        "## Upload the classified image to Earth Engine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXulMNl9lTDv",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "print('Uploading to ' + OUTPUT_ASSET_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V64tcVxsO5h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start the upload.\n",
        "# json_file = 'gs://water-classification-sensitivity/Image_pixel_laos_mixer.json'\n",
        "\n",
        "print(json_file)\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4HyhUU_Bal",
        "colab_type": "text"
      },
      "source": [
        "## Check the status of the asset ingestion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vB-gwGhl_3C",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "ee.batch.Task.list()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvXvy9GDhM-p",
        "colab_type": "text"
      },
      "source": [
        "## View the ingested asset in GEE\n",
        "\n"
      ]
    }
  ]
}